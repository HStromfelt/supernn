{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- All imports necessary for the cell are made in the cell, that way never have to run around running cells in a special order!\n",
    " - However! Do need to run the main setup first so the root logger gets set\n",
    " \n",
    "- Also, when running the setup a bunch of times, many loggers seem to get made and the outputs get sent out many times..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Logger and Other important stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T14:51:40.944323Z",
     "start_time": "2017-08-24T14:51:39.788303Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:51:40 [supernn.admin.log   ] [WARNING ] : NOT using tcmalloc\n"
     ]
    }
   ],
   "source": [
    "import os, os.path\n",
    "from supernn.admin import Log\n",
    "\n",
    "## Init: Main Setup\n",
    "log_dir = os.path.join(os.getcwd(), '../data/')\n",
    "debug_mode = True\n",
    "generate_log_dir = True\n",
    "config_path = './config.ini'\n",
    "\n",
    "args = dict(\n",
    "    log_dir=log_dir,\n",
    "    debug_mode=debug_mode,\n",
    "    gen_log_dir=generate_log_dir,\n",
    "    config_path=config_path\n",
    ")\n",
    "\n",
    "## Init: Set up logger\n",
    "name = 'error_ordering_test'  # Usually set when starting program from command line\n",
    "prefix = name + '_supernn' if name != '' else supernn\n",
    "\n",
    "args['name'] = name\n",
    "args['prefix'] = prefix\n",
    "\n",
    "log = Log.setup_log_with_args(args)\n",
    "if not args['debug_mode']:\n",
    "    log.info('Running in INFO mode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T14:51:41.043426Z",
     "start_time": "2017-08-24T14:51:40.945891Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import inspect\n",
    "\n",
    "import supernn.util as util\n",
    "from supernn.admin import Reporter, Experiment, Log\n",
    "from supernn.nn import GraphConstructor, Activations; activations = Activations().__dict__\n",
    "from supernn.datasets import DataInterface\n",
    "\n",
    "class Runner(Experiment):\n",
    "    \"\"\"Parse config and then prepare/run the extracted experiments\"\"\"\n",
    "    \n",
    "    def __init__(self, config_path, experiment_name):\n",
    "        \"\"\"\n",
    "        Experiment superclass __init__ provides:\n",
    "            config_manager: Class that interfaces with .ini \n",
    "                config file and allows us to get different config parameters\n",
    "            exp_configs: Config per experiment, obtained by running the \n",
    "                parse_experiments_config function which needs to be declared here\n",
    "        \"\"\"\n",
    "        super().__init__(config_path, experiment_name)\n",
    "        \n",
    "    # Overriding from Experiment ~Abstract class\n",
    "    def parse_experiments_config(self):\n",
    "        \"\"\"Unpack config\"\"\"\n",
    "        log.info('===Parsing Experiment Config===')\n",
    "        experiments = []\n",
    "        \n",
    "        # Dataset (loaded from corresponding data loader in lib)\n",
    "        dataset = self.config_manager.get_config('dataset')\n",
    "        \n",
    "        # 2D Convolution (1)\n",
    "        conv2d_1_detail = self.config_manager.get_config('conv2d_1', as_type=int)\n",
    "        conv2d_1_activation = activations[self.config_manager.get_config('conv2d_1_activation')]\n",
    "        conv2d_1 = dict(\n",
    "            x = conv2d_1_detail[0],\n",
    "            y = conv2d_1_detail[1],\n",
    "            channels = conv2d_1_detail[2],\n",
    "            features = conv2d_1_detail[3],\n",
    "            activation = conv2d_1_activation\n",
    "        )\n",
    "        \n",
    "        # 2D Convolution (2)\n",
    "        conv2d_2_detail = self.config_manager.get_config('conv2d_2', as_type=int)\n",
    "        conv2d_2_activation = activations[self.config_manager.get_config('conv2d_2_activation')]\n",
    "        conv2d_2 = dict(\n",
    "            x = conv2d_2_detail[0],\n",
    "            y = conv2d_2_detail[1],\n",
    "            channels = conv2d_2_detail[2],\n",
    "            features = conv2d_2_detail[3],\n",
    "            activation = conv2d_2_activation\n",
    "        )\n",
    "        \n",
    "        # Fully connected Layer\n",
    "        fcon_1 = dict(\n",
    "            nodes = self.config_manager.get_config('fcon_1', as_type=int),\n",
    "            activation = activations[self.config_manager.get_config('fcon_1_activation')]\n",
    "        )\n",
    "        \n",
    "        # Hyperparameters\n",
    "        learning_rate = self.config_manager.get_config('base_learning_rate', as_type=float)\n",
    "        batch_size = self.config_manager.get_config('batch_size', as_type=int)\n",
    "        max_steps = self.config_manager.get_config('max_steps', as_type=int)\n",
    "        optimiser = self.config_manager.get_config('optimiser')\n",
    "        \n",
    "        name = 'conv_lr_{}'.format(learning_rate)\n",
    "        \n",
    "        args = dict(\n",
    "            dataset=dataset,\n",
    "            conv2d_1=conv2d_1,\n",
    "            conv2d_2=conv2d_2,\n",
    "            fcon_1=fcon_1,\n",
    "            learning_rate=learning_rate,\n",
    "            batch_size=batch_size,\n",
    "            max_steps=max_steps,\n",
    "            optimiser=optimiser,\n",
    "            name=name\n",
    "        )\n",
    "        \n",
    "        experiments.append(args)\n",
    "        \n",
    "        return experiments\n",
    "    \n",
    "    def run(self):\n",
    "        start = time.time()\n",
    "        for exp_args in self.exp_configs:\n",
    "            log.debug('Running experiment with args: {}'.format(exp_args))\n",
    "            self.run_experiment(exp_args)\n",
    "        log.debug('Finished experiments after %.2fs', time.time() - start)\n",
    "    \n",
    "    def run_experiment(self, config):\n",
    "        start = time.time()\n",
    "        # prepare savable config\n",
    "        s_config = {k: (v if not callable(v) else v.__name__) for k, v in config.items()}\n",
    "        log.debug('experiment config: {}'.format(s_config))\n",
    "        self.save_subexp_config(s_config, s_config['name'] + '/')\n",
    "        \n",
    "        config['data_interface'] = DataInterface(data_name=config['dataset'])\n",
    "        \n",
    "        # Set where tensorboard output should go. \n",
    "        # Name usually dictated by commandline input,\n",
    "        # but here it is set in above cell\n",
    "        Reporter.set_tensorboard_dir(Log.log_dir + 'tensorboard_{}/'.format(config['name']))\n",
    "        \n",
    "        # This runs the learner process\n",
    "        Learner(config).run()\n",
    "            \n",
    "        \n",
    "        log.debug('Finished experiment after %.2fs', time.time() - start)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T14:51:41.396535Z",
     "start_time": "2017-08-24T14:51:41.045027Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from supernn.admin import Reporter, Log; log = Log.get_logger(__name__)\n",
    "from supernn.nn import InputLayer, FullyConnected, Convolution2D, OutputLayer\n",
    "\n",
    "## Responsible for taking config and running the experiment\n",
    "class Learner(object):\n",
    "    \n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        self.metrics = None  # tensorflow metrics/ops for model to function\n",
    "        \n",
    "        self.graphs = dict(\n",
    "            tensorflow=None,\n",
    "            conv2d_graph=None\n",
    "        )\n",
    "    \n",
    "    def run(self):\n",
    "        # Setup model and graph\n",
    "        tf_graph = tf.Graph()\n",
    "        self.graphs['tensorflow'] = tf_graph  # Incase we start using more than one graph.. bcz ideazzzzzzzz\n",
    "        with tf_graph.as_default():\n",
    "            self.prepare_data_loader()\n",
    "            self.build_model()  # sets custom graph\n",
    "            self.assign_metrics() \n",
    "            self.create_and_run_session()\n",
    "    \n",
    "    #####\n",
    "    \n",
    "    def prepare_data_loader(self):\n",
    "        self.args['input_data'] = self.args['data_interface'].loader.load_data()\n",
    "    \n",
    "    def build_model(self):\n",
    "        \"\"\"Test Graph Constructor\"\"\"\n",
    "        log.debug('===Constructing Graph===')\n",
    "        \n",
    "        graph = GraphConstructor()\n",
    "        \n",
    "        # Data interface, \n",
    "        data_interface = self.args['data_interface']\n",
    "        dataset = data_interface.dataset\n",
    "        \n",
    "        \n",
    "        # Layer Config\n",
    "        # input_dict\n",
    "        input_1 = InputLayer(\n",
    "            dataset['shape'][0], \n",
    "            dataset['dtype'], \n",
    "            layer_type=dataset['shape_type'], \n",
    "            toConv='conv2d',  # conv2d as next layer is a conv2d\n",
    "            data_interface=data_interface, \n",
    "            name='input'\n",
    "        )\n",
    "        \n",
    "        # conv_dict\n",
    "        conv2d_1 = Convolution2D(\n",
    "            self.args['conv2d_1']['activation'], \n",
    "            self.args['conv2d_1']['x'], \n",
    "            self.args['conv2d_1']['y'], \n",
    "            self.args['conv2d_1']['channels'], \n",
    "            self.args['conv2d_1']['features'], \n",
    "            prev_layer='input', \n",
    "            name='conv2d_1'\n",
    "        )\n",
    "        \n",
    "        conv2d_2 = Convolution2D(\n",
    "            self.args['conv2d_2']['activation'], \n",
    "            self.args['conv2d_2']['x'], \n",
    "            self.args['conv2d_2']['y'], \n",
    "            self.args['conv2d_2']['channels'], \n",
    "            self.args['conv2d_2']['features'], \n",
    "            prev_layer='conv2d_1', \n",
    "            name='conv2d_2'\n",
    "        )\n",
    "        \n",
    "        # fully_con_dict\n",
    "        fCon_1 = FullyConnected(\n",
    "            self.args['fcon_1']['activation'], \n",
    "            self.args['fcon_1']['nodes'], \n",
    "            'conv2d_2', \n",
    "            name='fcon_1'\n",
    "        )\n",
    "        \n",
    "        # out_dict TODO:: Nothing in config for output... can there be anything useful there?\n",
    "        out_1 = OutputLayer(\n",
    "            tf.matmul, \n",
    "            10, \n",
    "            prev_layer='fcon_1', \n",
    "            name='out_1'\n",
    "        )\n",
    "\n",
    "        graph.generate_graph_structure(\n",
    "            properties=[\n",
    "                ('input', input_1), \n",
    "                ('conv2d', conv2d_1), \n",
    "                ('conv2d', conv2d_2), \n",
    "                ('fully_connected', fCon_1), \n",
    "                ('output', out_1)\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "        self.graphs['conv2d_graph'] = graph\n",
    "        \n",
    "    def assign_metrics(self):\n",
    "        log.info('===Assigning metrics===')\n",
    "        # Specify metrics\n",
    "        target_output = tf.placeholder(\n",
    "            tf.float32, \n",
    "            shape=[\n",
    "                None, \n",
    "                self.graphs['conv2d_graph'].model.model_named_layers['out_1'].output.get_shape().as_list()[1]\n",
    "            ]\n",
    "        )\n",
    "        predicted_output = self.graphs['conv2d_graph'].model.model_named_layers['out_1'].output\n",
    "\n",
    "        with tf.name_scope('cross_entropy'):\n",
    "            diff = tf.nn.softmax_cross_entropy_with_logits(labels=target_output, logits=predicted_output)\n",
    "            with tf.name_scope('total'):\n",
    "                loss = tf.reduce_mean(diff)\n",
    "        Reporter.report_scalar(loss, 'cross_entropy')\n",
    "\n",
    "        with tf.name_scope('accuracy'):\n",
    "            with tf.name_scope('correct_prediction'):\n",
    "                correct_prediction = tf.equal(tf.argmax(predicted_output, 1), tf.argmax(target_output, 1))\n",
    "            with tf.name_scope('accuracy'):\n",
    "                accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        Reporter.report_scalar(accuracy, 'accuracy')\n",
    "\n",
    "        merger = Reporter.merge_summaries()\n",
    "        \n",
    "        train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "        x = self.graphs['conv2d_graph'].model.model_named_layers['input'].input_data\n",
    "        \n",
    "        ## Append metrics to experiment arguments (Necessary for session runner)\n",
    "        self.args['x'] = x\n",
    "        self.args['train_step'] = train_step\n",
    "        self.args['merger'] = merger\n",
    "        self.args['accuracy'] = accuracy\n",
    "        self.args['target_output'] = target_output\n",
    "        self.args['predicted_output'] = predicted_output\n",
    "    \n",
    "    def create_and_run_session(self):\n",
    "        log.info('===Preparing Session and Running===')\n",
    "        \n",
    "        # For clarity, unwrapping some args\n",
    "        mnist = self.args['input_data']\n",
    "        train_step = self.args['train_step']\n",
    "        merger = self.args['merger']\n",
    "        target_output = self.args['target_output']\n",
    "        predicted_output = self.args['predicted_output']\n",
    "        x = self.args['x']\n",
    "        accuracy = self.args['accuracy']\n",
    "        \n",
    "        # Intialising important variables\n",
    "        pass_schedule = ['Full', 'Ordered', 'Full']  # Full pass (Standard batching), Ordered pass (follow new batches)\n",
    "        prioritised_batch_sets = []\n",
    "        is_custom_pass = False\n",
    "        custom_batch = []\n",
    "        batches_in_epoch = int(mnist.train.num_examples/self.args['batch_size'])\n",
    "        \n",
    "        # Helper function - Better in scope for variables access\n",
    "        def feed_dict(train, custom=False, custom_batch=[]):\n",
    "            \"\"\"Generate Tensorflow feed_dict: maps data onto Tensor placeholders.\"\"\"\n",
    "            if train:\n",
    "                if custom:\n",
    "                    # do stuff with custom batch\n",
    "                    xs, ys = custom_batch\n",
    "                else:\n",
    "                    xs, ys = mnist.train.next_batch(self.args['batch_size'])\n",
    "            else:\n",
    "                xs, ys = mnist.test.images, mnist.test.labels\n",
    "\n",
    "            # Load values into Tensorflow variables (accessible in instance args)\n",
    "            return {x: xs, target_output: ys}\n",
    "        \n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            # Initialise all tensorflow variables (otherwise cannot use them)\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "            # Set up Tensorboard\n",
    "            train_writer = Reporter.set_writer_path('train', sess.graph)\n",
    "            test_writer = Reporter.set_writer_path('test')\n",
    "            \n",
    "            Reporter.set_saver(tf.train.Saver())\n",
    "            \n",
    "            batch_index = 0\n",
    "            for epoch in range(len(pass_schedule)):  # Loop while schedules not finished\n",
    "                for batch_index in range(batches_in_epoch):\n",
    "                    # If doing a custom pass, need to use the \n",
    "                    # prioritised set of batches generated in full pass\n",
    "                    if is_custom_pass:\n",
    "                        custom_batch = prioritised_batch_sets[batch_index]\n",
    "\n",
    "                    if batch_index % 50 == 0:\n",
    "                        summary, acc = sess.run([merger, accuracy], feed_dict=feed_dict(False))\n",
    "                        test_writer.add_summary(summary, batch_index + epoch * batches_in_epoch)\n",
    "                        log.debug('== Testing - Accuracy at batch step %s: %s =='% (batch_index + epoch * batches_in_epoch, acc))\n",
    "                    else: \n",
    "                        # Training:\n",
    "                        # Run training and obtain summaries\n",
    "                        # Also capture the expected vs predicted output,\n",
    "                        # necessary for new batch creation\n",
    "                        log.debug('== TRAINING - Mode: {} - Batch: {} =='.format(pass_schedule[epoch], batch_index))\n",
    "                        if batch_index % 100 == 99:\n",
    "                            run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "                            run_metadata = tf.RunMetadata()\n",
    "                            summary, _, target, predicted, samples = sess.run(\n",
    "                                [merger, train_step, target_output, predicted_output, x], \n",
    "                                feed_dict=feed_dict(True, custom=is_custom_pass, custom_batch=custom_batch),\n",
    "                                options=run_options,\n",
    "                                run_metadata=run_metadata\n",
    "                            )\n",
    "                            train_writer.add_run_metadata(run_metadata, 'step %d' % batch_index + epoch * batches_in_epoch)\n",
    "                            train_writer.add_summary(summary, batch_index + epoch * batches_in_epoch)\n",
    "                        else:\n",
    "                            summary, _, target, predicted, samples = sess.run(\n",
    "                                [merger, train_step, target_output, predicted_output, x],\n",
    "                                feed_dict=feed_dict(True, custom=is_custom_pass, custom_batch=custom_batch)\n",
    "                            )\n",
    "                            train_writer.add_summary(summary, batch_index + epoch * batches_in_epoch)\n",
    "\n",
    "                        # Check if we are in a Full (standard batching) pass\n",
    "                        # if yes, then have to create the ordered batches\n",
    "                        # ready for a prioritised batching pass\n",
    "                        if not is_custom_pass:\n",
    "                            # Get samples that failed\n",
    "                            # TODO: Also capture their feature vectors\n",
    "                            wrongens = []\n",
    "                            wrongens_priority_index = []\n",
    "                            rightens = []\n",
    "                            rightens_priority_index = []\n",
    "                            for res_i in range(len(target)):\n",
    "                                if tf.argmax(predicted[res_i],1) != tf.argmax(target[res_i], 1):\n",
    "                                    # Input and expected label, associated with the \n",
    "                                    # output that caused the prediction error.\n",
    "                                    # These are needed for the created batches\n",
    "                                    wrongens.append([samples[res_i], target[res_i]])\n",
    "                                    wrongens_priority_index.append()\n",
    "                                else:\n",
    "                                    # Also log the successful example, so they\n",
    "                                    # can be used to shuffle into the prioritised batched\n",
    "                                    # e.g. wrong examples later in the program are more\n",
    "                                    # important as it is possible the first errors can be\n",
    "                                    # classified as a result of training. This isn't true \n",
    "                                    # for the errors after plenty of training.\n",
    "                                    rightens.append([samples[res_i], target[res_i]])\n",
    "                            prioritised_batch_sets.append(wrongens)\n",
    "                \n",
    "                \n",
    "                log.debug('== Reached End of Epoch, Number: {} =='.format(epoch))\n",
    "                from IPython.core.debugger import Tracer; Tracer()()\n",
    "\n",
    "                # Test progress\n",
    "                log.debug('== TESTING ==')\n",
    "                summary, acc = sess.run([merger, accuracy], feed_dict=feed_dict(False))\n",
    "                test_writer.add_summary(summary, epoch * batches_in_epoch)\n",
    "                log.debug('Test Set -- End of Epoch: {} -- Accuracy: {}'.format(epoch, acc))\n",
    "\n",
    "\n",
    "                if pass_schedule[epoch] == 'Ordered':\n",
    "                    log.debug('===Running Ordered Pass===')\n",
    "                    is_custom_pass = True\n",
    "                else:\n",
    "                    log.debug('===Running Standard Pass===')\n",
    "                    prioritised_batch_sets = []  # Will fill this during pass for ordered run\n",
    "                    is_custom_pass = False\n",
    "                    custom_batch = []\n",
    "            \n",
    "            log.info('===Reached End of Scheduled Passes===')\n",
    "            Reporter.save_checkpoint(sess)\n",
    "            Reporter.save_model_meta()\n",
    "            \n",
    "            sess.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T14:53:21.393933Z",
     "start_time": "2017-08-24T14:51:41.397957Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:51:41 [supernn.admin.configuration] [DEBUG   ] : Extracting parameters for experiment_error_ordering from path ./config.ini\n",
      "15:51:41 [supernn.admin.experiment] [DEBUG   ] : Starting experiment with config <Section: experiment_error_ordering>\n",
      "15:51:41 [__main__            ] [INFO    ] : ===Parsing Experiment Config===\n",
      "15:51:41 [__main__            ] [DEBUG   ] : Running experiment with args: {'dataset': 'MNIST', 'conv2d_1': {'x': 5, 'y': 5, 'channels': 1, 'features': 32, 'activation': <function relu at 0x7f194c92b7b8>}, 'conv2d_2': {'x': 5, 'y': 5, 'channels': 32, 'features': 64, 'activation': <function relu at 0x7f194c92b7b8>}, 'fcon_1': {'nodes': 1024, 'activation': <function relu at 0x7f194c92b7b8>}, 'learning_rate': 0.01, 'batch_size': 100, 'max_steps': 600, 'optimiser': 'ADAM', 'name': 'conv_lr_0.01'}\n",
      "15:51:41 [__main__            ] [DEBUG   ] : experiment config: {'dataset': 'MNIST', 'conv2d_1': {'x': 5, 'y': 5, 'channels': 1, 'features': 32, 'activation': <function relu at 0x7f194c92b7b8>}, 'conv2d_2': {'x': 5, 'y': 5, 'channels': 32, 'features': 64, 'activation': <function relu at 0x7f194c92b7b8>}, 'fcon_1': {'nodes': 1024, 'activation': <function relu at 0x7f194c92b7b8>}, 'learning_rate': 0.01, 'batch_size': 100, 'max_steps': 600, 'optimiser': 'ADAM', 'name': 'conv_lr_0.01'}\n",
      "15:51:41 [supernn.datasets.data_loader] [INFO    ] : Loading MNIST data to directory ./MNIST_data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:51:48 [__main__            ] [DEBUG   ] : ===Constructing Graph===\n",
      "15:51:48 [__main__            ] [INFO    ] : ===Assigning metrics===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "structure: ('input', <supernn.nn.layers.InputLayer object at 0x7f194367ffd0>)\n",
      "depth: 0\n",
      "class props: <supernn.nn.layers.InputLayer object at 0x7f194367ffd0>\n",
      "adding input layer\n",
      "setting input to conv2d shape\n",
      "structure: ('conv2d', <supernn.nn.layers.Convolution2D object at 0x7f194363f6d8>)\n",
      "depth: 1\n",
      "class props: <supernn.nn.layers.Convolution2D object at 0x7f194363f6d8>\n",
      "adding conv2d layer\n",
      "structure: ('conv2d', <supernn.nn.layers.Convolution2D object at 0x7f194363fa20>)\n",
      "depth: 2\n",
      "class props: <supernn.nn.layers.Convolution2D object at 0x7f194363fa20>\n",
      "adding conv2d layer\n",
      "structure: ('fully_connected', <supernn.nn.layers.FullyConnected object at 0x7f194363f748>)\n",
      "depth: 3\n",
      "class props: <supernn.nn.layers.FullyConnected object at 0x7f194363f748>\n",
      "adding fully connected layer\n",
      "structure: ('output', <supernn.nn.layers.OutputLayer object at 0x7f19436ce0f0>)\n",
      "depth: 4\n",
      "class props: <supernn.nn.layers.OutputLayer object at 0x7f19436ce0f0>\n",
      "adding output layer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:51:48 [__main__            ] [INFO    ] : ===Preparing Session and Running===\n",
      "15:51:55 [__main__            ] [DEBUG   ] : == Testing - Accuracy at batch step 0: 0.0982 ==\n",
      "15:51:55 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 1 ==\n",
      "15:51:56 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 2 ==\n",
      "15:51:56 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 3 ==\n",
      "15:51:57 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 4 ==\n",
      "15:51:57 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 5 ==\n",
      "15:51:58 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 6 ==\n",
      "15:51:58 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 7 ==\n",
      "15:51:59 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 8 ==\n",
      "15:51:59 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 9 ==\n",
      "15:52:00 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 10 ==\n",
      "15:52:00 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 11 ==\n",
      "15:52:01 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 12 ==\n",
      "15:52:01 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 13 ==\n",
      "15:52:02 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 14 ==\n",
      "15:52:03 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 15 ==\n",
      "15:52:03 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 16 ==\n",
      "15:52:04 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 17 ==\n",
      "15:52:04 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 18 ==\n",
      "15:52:05 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 19 ==\n",
      "15:52:06 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 20 ==\n",
      "15:52:06 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 21 ==\n",
      "15:52:07 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 22 ==\n",
      "15:52:07 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 23 ==\n",
      "15:52:08 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 24 ==\n",
      "15:52:08 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 25 ==\n",
      "15:52:09 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 26 ==\n",
      "15:52:10 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 27 ==\n",
      "15:52:10 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 28 ==\n",
      "15:52:11 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 29 ==\n",
      "15:52:12 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 30 ==\n",
      "15:52:12 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 31 ==\n",
      "15:52:13 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 32 ==\n",
      "15:52:14 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 33 ==\n",
      "15:52:14 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 34 ==\n",
      "15:52:15 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 35 ==\n",
      "15:52:16 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 36 ==\n",
      "15:52:16 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 37 ==\n",
      "15:52:17 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 38 ==\n",
      "15:52:18 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 39 ==\n",
      "15:52:19 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 40 ==\n",
      "15:52:19 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 41 ==\n",
      "15:52:20 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 42 ==\n",
      "15:52:21 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 43 ==\n",
      "15:52:22 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 44 ==\n",
      "15:52:22 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 45 ==\n",
      "15:52:23 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 46 ==\n",
      "15:52:24 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 47 ==\n",
      "15:52:25 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 48 ==\n",
      "15:52:26 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 49 ==\n",
      "15:52:32 [__main__            ] [DEBUG   ] : == Testing - Accuracy at batch step 50: 0.8133 ==\n",
      "15:52:32 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 51 ==\n",
      "15:52:33 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 52 ==\n",
      "15:52:33 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 53 ==\n",
      "15:52:34 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 54 ==\n",
      "15:52:35 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 55 ==\n",
      "15:52:36 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 56 ==\n",
      "15:52:37 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 57 ==\n",
      "15:52:38 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 58 ==\n",
      "15:52:39 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 59 ==\n",
      "15:52:40 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 60 ==\n",
      "15:52:40 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 61 ==\n",
      "15:52:41 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 62 ==\n",
      "15:52:42 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 63 ==\n",
      "15:52:43 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 64 ==\n",
      "15:52:44 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 65 ==\n",
      "15:52:45 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 66 ==\n",
      "15:52:46 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 67 ==\n",
      "15:52:47 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 68 ==\n",
      "15:52:48 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 69 ==\n",
      "15:52:49 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 70 ==\n",
      "15:52:50 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 71 ==\n",
      "15:52:51 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 72 ==\n",
      "15:52:52 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 73 ==\n",
      "15:52:53 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 74 ==\n",
      "15:52:54 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 75 ==\n",
      "15:52:55 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 76 ==\n",
      "15:52:56 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 77 ==\n",
      "15:52:57 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 78 ==\n",
      "15:52:58 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 79 ==\n",
      "15:52:59 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 80 ==\n",
      "15:53:00 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 81 ==\n",
      "15:53:01 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 82 ==\n",
      "15:53:02 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 83 ==\n",
      "15:53:03 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 84 ==\n",
      "15:53:04 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 85 ==\n",
      "15:53:05 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 86 ==\n",
      "15:53:06 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 87 ==\n",
      "15:53:07 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 88 ==\n",
      "15:53:08 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 89 ==\n",
      "15:53:09 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 90 ==\n",
      "15:53:10 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 91 ==\n",
      "15:53:11 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 92 ==\n",
      "15:53:13 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 93 ==\n",
      "15:53:14 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 94 ==\n",
      "15:53:15 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 95 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:53:16 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 96 ==\n",
      "15:53:17 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 97 ==\n",
      "15:53:19 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 98 ==\n",
      "15:53:20 [__main__            ] [DEBUG   ] : == TRAINING - Mode: Full - Batch: 99 ==\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "must be str, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8e4b537469fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrunner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRunner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'experiment_error_ordering'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-ff852341f74d>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mexp_args\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp_configs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running experiment with args: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Finished experiments after %.2fs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-ff852341f74d>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;31m# This runs the learner process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mLearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-86080f5bd49c>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# sets custom graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_and_run_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m#####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-86080f5bd49c>\u001b[0m in \u001b[0;36mcreate_and_run_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    243\u001b[0m                             \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                         )\n\u001b[0;32m--> 245\u001b[0;31m                         \u001b[0mtrain_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_run_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'step %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepochs_completed\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mepoch_total_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m                         \u001b[0mtrain_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepochs_completed\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mepoch_total_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: must be str, not int"
     ]
    }
   ],
   "source": [
    "runner = Runner(args['config_path'], 'experiment_error_ordering').run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "48px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
